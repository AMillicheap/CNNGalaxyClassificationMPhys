{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import argparse\n",
    "import configparser as ConfigParser\n",
    "import ast\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "from matplotlib.offsetbox import (OffsetImage, AnnotationBbox)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"\n",
    "        Parse the command line arguments\n",
    "        \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-C','--config', default=\"myconfig.txt\", required=True, help='Name of the input config file')\n",
    "    \n",
    "    args, __ = parser.parse_known_args()\n",
    "    \n",
    "    return vars(args)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def parse_config(filename):\n",
    "    \n",
    "    config = ConfigParser.SafeConfigParser(allow_no_value=True)\n",
    "    config.read(filename)\n",
    "    \n",
    "    # Build a nested dictionary with tasknames at the top level\n",
    "    # and parameter values one level down.\n",
    "    taskvals = dict()\n",
    "    for section in config.sections():\n",
    "        \n",
    "        if section not in taskvals:\n",
    "            taskvals[section] = dict()\n",
    "        \n",
    "        for option in config.options(section):\n",
    "            # Evaluate to the right type()\n",
    "            try:\n",
    "                taskvals[section][option] = ast.literal_eval(config.get(section, option))\n",
    "            except (ValueError,SyntaxError):\n",
    "                err = \"Cannot format field '{0}' in config file '{1}'\".format(option,filename)\n",
    "                err += \", which is currently set to {0}. Ensure strings are in 'quotes'.\".format(config.get(section, option))\n",
    "                raise ValueError(err)\n",
    "\n",
    "    return taskvals, config\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def build_mask(s, margin=2, dtype=torch.float32):\n",
    "    mask = torch.zeros(1, 1, s, s, dtype=dtype)\n",
    "    c = (s-1) / 2\n",
    "    t = (c - margin/100.*c)**2\n",
    "    sig = 2.\n",
    "    for x in range(s):\n",
    "        for y in range(s):\n",
    "            r = (x - c) ** 2 + (y - c) ** 2\n",
    "            if r > t:\n",
    "                mask[..., x, y] = math.exp((t - r)/sig**2)\n",
    "            else:\n",
    "                mask[..., x, y] = 1.\n",
    "    return mask\n",
    "    \n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def train(model, trainloader, optimiser, device):\n",
    "\n",
    "    train_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (data, labels) in enumerate(trainloader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        p_y = F.softmax(model(data), dim=1)\n",
    "        loss = model.loss(p_y, labels)\n",
    "            \n",
    "        train_loss += loss.item() * data.size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "    train_loss /= len(trainloader.dataset)\n",
    "    return train_loss\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def test(model, testloader, device):\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, labels) in enumerate(testloader):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            p_y = F.softmax(model(data), dim=1)\n",
    "            loss = model.loss(p_y, labels)\n",
    "                \n",
    "            test_loss += loss.item() * data.size(0)\n",
    "\n",
    "            preds = p_y.argmax(dim=1, keepdim=True)\n",
    "            correct += preds.eq(labels.view_as(preds)).sum().item()\n",
    "\n",
    "        test_loss /= len(testloader.dataset)\n",
    "        accuracy = correct / len(testloader.dataset)\n",
    "\n",
    "    return test_loss, accuracy\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def test_mc(model, testloader, device, T=100):\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    model.enable_dropout()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, labels) in enumerate(testloader):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            _prob = torch.zeros(labels.size()[0],2).to(device=device)\n",
    "            for _ in range(T):\n",
    "                p_y = F.softmax(model(data), dim=1)\n",
    "                _prob += p_y\n",
    "                \n",
    "            _prob /= T\n",
    "            loss = model.loss(_prob,labels)\n",
    "            \n",
    "            test_loss += loss.item() * data.size(0)\n",
    "\n",
    "            preds = p_y.argmax(dim=1, keepdim=True)\n",
    "            correct += preds.eq(labels.view_as(preds)).sum().item()\n",
    "\n",
    "        test_loss /= len(testloader.dataset)\n",
    "        accuracy = correct / len(testloader.dataset)\n",
    "\n",
    "    return test_loss, accuracy\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def positionimage(x, y, ax, ar, zoom=0.5):\n",
    "    \"\"\"Place image from file `fname` into axes `ax` at position `x,y`.\"\"\"\n",
    "    \n",
    "    imsize = ar.shape[0]\n",
    "    if imsize==151: zoom=0.24\n",
    "    if imsize==51: zoom = 0.75\n",
    "    im = OffsetImage(ar, zoom=zoom)\n",
    "    im.image.axes = ax\n",
    "    \n",
    "    ab = AnnotationBbox(im, (x,y), xycoords='data')\n",
    "    ax.add_artist(ab)\n",
    "    \n",
    "    return\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def make_linemarker(x,y,dx,col,ax):\n",
    "    \n",
    "    xs = [x-0.5*dx,x+0.5*dx]\n",
    "    for i in range(0,y.shape[0]):\n",
    "        ys = [y[i],y[i]]\n",
    "        ax.plot(xs,ys,marker=\",\",c=col,alpha=0.1,lw=5)\n",
    "    \n",
    "    return\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def fr_rotation_test(model, data, target, idx, device):\n",
    "    \n",
    "    T = 100\n",
    "    rotation_list = range(0, 180, 20)\n",
    "    #print(\"True classification: \",target[0].item())\n",
    "    \n",
    "    image_list = []\n",
    "    outp_list = []\n",
    "    inpt_list = []\n",
    "    for r in rotation_list:\n",
    "        \n",
    "        # make rotated image:\n",
    "        rotation_matrix = torch.Tensor([[[np.cos(r/360.0*2*np.pi), -np.sin(r/360.0*2*np.pi), 0],\n",
    "                                         [np.sin(r/360.0*2*np.pi), np.cos(r/360.0*2*np.pi), 0]]]).to(device)\n",
    "        grid = F.affine_grid(rotation_matrix, data.size(), align_corners=True)\n",
    "        data_rotate = F.grid_sample(data, grid, align_corners=True)\n",
    "        image_list.append(data_rotate)\n",
    "        \n",
    "        # get straight prediction:\n",
    "        model.eval()\n",
    "        x = model(data_rotate)\n",
    "        p = F.softmax(x,dim=1)\n",
    "                                         \n",
    "        # run 100 stochastic forward passes:\n",
    "        model.enable_dropout()\n",
    "        output_list, input_list = [], []\n",
    "        for i in range(T):\n",
    "            x = model(data_rotate)\n",
    "            input_list.append(torch.unsqueeze(x, 0).cpu())\n",
    "            output_list.append(torch.unsqueeze(F.softmax(x,dim=1), 0).cpu())\n",
    "                                         \n",
    "        # calculate the mean output for each target:\n",
    "        output_mean = np.squeeze(torch.cat(output_list, 0).mean(0).data.cpu().numpy())\n",
    "                                             \n",
    "        # append per rotation output into list:\n",
    "        outp_list.append(np.squeeze(torch.cat(output_list, 0).data.numpy()))\n",
    "        inpt_list.append(np.squeeze(torch.cat(input_list, 0).data.numpy()))\n",
    "\n",
    "        #print ('rotation degree', str(r), 'Predict : {} - {}'.format(output_mean.argmax(),output_mean))\n",
    "\n",
    "    preds = np.array([0,1])\n",
    "    classes = np.array([\"FRI\",\"FRII\"])\n",
    "    \n",
    "    outp_list = np.array(outp_list)\n",
    "    inpt_list = np.array(inpt_list)\n",
    "    rotation_list = np.array(rotation_list)\n",
    "\n",
    "    colours=[\"b\",\"r\"]\n",
    "\n",
    "    #fig1, (a0, a1) = pl.subplots(2, 1, gridspec_kw={'height_ratios': [8,1]})\n",
    "    fig2, (a2, a3) = pl.subplots(2, 1, gridspec_kw={'height_ratios': [8,1]})\n",
    "\n",
    "    eta = np.zeros(len(rotation_list))\n",
    "    for i in range(len(rotation_list)):\n",
    "        x = outp_list[i,:,0]\n",
    "        y = outp_list[i,:,1]\n",
    "        eta[i] = overlapping(x, y)\n",
    "\n",
    "    #a0.set_title(\"Input\")\n",
    "    if np.mean(eta)>=0.01:\n",
    "        a2.set_title(r\"$\\langle \\eta \\rangle = $ {:.2f}\".format(np.mean(eta)))\n",
    "    else:\n",
    "        a2.set_title(r\"$\\langle \\eta \\rangle < 0.01$\")\n",
    "\n",
    "    dx = 0.8*(rotation_list[1]-rotation_list[0])\n",
    "    for pred in preds:\n",
    "        col = colours[pred]\n",
    "        #a0.plot(rotation_list[0],inpt_list[0,0,pred],marker=\",\",c=col,label=str(pred))\n",
    "        a2.plot(rotation_list[0],outp_list[0,0,pred],marker=\",\",c=col,label=classes[pred])\n",
    "        for i in range(rotation_list.shape[0]):\n",
    "        #    make_linemarker(rotation_list[i],inpt_list[i,:,pred],dx,col,a0)\n",
    "            make_linemarker(rotation_list[i],outp_list[i,:,pred],dx,col,a2)\n",
    "        \n",
    "    #a2.plot(rotation_list, eta)\n",
    "    \n",
    "    #a0.legend()\n",
    "    a2.legend(loc='center right')\n",
    "    #a0.axis([0,180,0,1])\n",
    "    #a0.set_xlabel(\"Rotation [deg]\")\n",
    "    a2.set_xlabel(\"Rotation [deg]\")\n",
    "    #a1.axis([0,180,0,1])\n",
    "    a3.axis([0,180,0,1])\n",
    "    #a1.axis('off')\n",
    "    a3.axis('off')\n",
    "    \n",
    "    imsize = data.size()[2]\n",
    "    mask = build_mask(imsize, margin=1)\n",
    "            \n",
    "    for i in range(len(rotation_list)):\n",
    "        inc = 0.5*(180./len(rotation_list))\n",
    "        #positionimage(rotation_list[i]+inc, 0., a1, image_list[i][0, 0, :, :].data.numpy(), zoom=0.32)\n",
    "        positionimage(rotation_list[i]+inc, 0., a3, mask[0,0,:,:]*image_list[i][0, 0, :, :].data.cpu().numpy(), zoom=0.32)\n",
    "        \n",
    "    \n",
    "    #fig1.tight_layout()\n",
    "    fig2.tight_layout()\n",
    "\n",
    "    #fig1.subplots_adjust(bottom=0.15)\n",
    "    fig2.subplots_adjust(bottom=0.15)\n",
    "\n",
    "    #pl.show()\n",
    "    fig2.savefig(\"./rotations/rotationtest_\"+str(idx)+\".png\")\n",
    "    \n",
    "    pl.close()\n",
    "    \n",
    "    return np.mean(eta), np.std(eta)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def overlapping(x, y, beta=0.1):\n",
    "\n",
    "    n_z = 100\n",
    "    z = np.linspace(0,1,n_z)\n",
    "    dz = 1./n_z\n",
    "    \n",
    "    norm = 1./(beta*np.sqrt(2*np.pi))\n",
    "    \n",
    "    n_x = len(x)\n",
    "    f_x = np.zeros(n_z)\n",
    "    for i in range(n_z):\n",
    "        for j in range(n_x):\n",
    "            f_x[i] += norm*np.exp(-0.5*(z[i] - x[j])**2/beta**2)\n",
    "        f_x[i] /= n_x\n",
    "    \n",
    "    \n",
    "    n_y = len(y)\n",
    "    f_y = np.zeros(n_z)\n",
    "    for i in range(n_z):\n",
    "        for j in range(n_y):\n",
    "            f_y[i] += norm*np.exp(-0.5*(z[i] - y[j])**2/beta**2)\n",
    "            \n",
    "        f_y[i] /= n_y\n",
    "    \n",
    "    \n",
    "    eta_z = np.zeros(n_z)\n",
    "    eta_z = np.minimum(f_x, f_y)\n",
    "        \n",
    "    #pl.subplot(111)\n",
    "    #pl.plot(z, f_x, label=r\"$f_x$\")\n",
    "    #pl.plot(z, f_y, label=r\"$f_y$\")\n",
    "    #pl.plot(z, eta_z, label=r\"$\\eta_z$\")\n",
    "    #pl.legend()\n",
    "    #pl.show()\n",
    "\n",
    "    return np.sum(eta_z)*dz\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def eval_overlap():\n",
    "\n",
    "    path1 = 'lenet_overlap.csv'\n",
    "    path2 = 'dn16_overlap.csv'\n",
    "    \n",
    "    df1 = pd.read_csv(path1)\n",
    "    df2 = pd.read_csv(path2)\n",
    "\n",
    "    targ1 = df1['target'].values\n",
    "    p1    = df1['softmax prob'].values\n",
    "    olap1 = df1['average overlap'].values\n",
    "    slap1 = df1['overlap variance'].values\n",
    "\n",
    "    targ2 = df2['target'].values\n",
    "    p2    = df2['softmax prob'].values\n",
    "    olap2 = df2['average overlap'].values\n",
    "    slap2 = df2['overlap variance'].values\n",
    "    \n",
    "    p1 = [np.array(p1[i].lstrip('[').rstrip(']').split(), dtype=float) for i in range(len(targ1))]\n",
    "    p2 = [np.array(p2[i].lstrip('[').rstrip(']').split(), dtype=float) for i in range(len(targ1))]\n",
    "    \n",
    "    p1 = np.array(p1)\n",
    "    p2 = np.array(p2)\n",
    "    \n",
    "    diff = olap1 - olap2\n",
    "\n",
    "    for i in range(len(targ1)):\n",
    "        print(\"{} {} {} {} {:.2f} {:.2f} {:.2f} {:.2f}\".format(i,targ1[i],np.argmax(p1[i,:]),np.argmax(p2[i,:]),olap1[i],olap2[i],slap1[i],slap2[i]))\n",
    "\n",
    "    better = diff[np.where(diff>0.01)]\n",
    "    better_class = targ1[np.where(diff>0.01)]\n",
    "    \n",
    "    worse = diff[np.where(diff<-0.01)]\n",
    "    worse_class = targ1[np.where(diff<-0.01)]\n",
    "    \n",
    "    print(\"Improved: \",len(better),np.mean(better),np.mean(better_class))\n",
    "    print(\"Worse: \",len(worse),np.mean(worse),np.mean(worse_class))\n",
    "    \n",
    "    print(\"Better:\")\n",
    "    for i in range(len(targ1)):\n",
    "        if diff[i]>0.01:\n",
    "            print(i, targ1[i], diff[i])\n",
    "            \n",
    "    print(\"Worse:\")\n",
    "    for i in range(len(targ1)):\n",
    "        if diff[i]<-0.01:\n",
    "            print(i, targ1[i], diff[i])\n",
    "    \n",
    "    print(\"Low D16:\")\n",
    "    n=0\n",
    "    for i in range(len(targ1)):\n",
    "        if olap2[i]<=0.01:\n",
    "            #print(i, targ2[i], olap2[i])\n",
    "            n+=1\n",
    "    print(n)\n",
    "   \n",
    "    print(\"Low e:\")\n",
    "    n=0\n",
    "    for i in range(len(targ1)):\n",
    "        if olap1[i]<=0.01:\n",
    "            #print(i, targ1[i], olap1[i])\n",
    "            n+=1\n",
    "    print(n)\n",
    "    \n",
    "    return\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
