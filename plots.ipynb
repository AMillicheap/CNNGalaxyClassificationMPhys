{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "from utils import *\n",
    "from MiraBest import MBFRConfident\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from matplotlib.ticker import ScalarFormatter,StrMethodFormatter\n",
    "\n",
    "#pl.rcParams[\"font.family\"] = \"Times\"\n",
    "pl.rcParams['font.size'] = 12\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def plot_err_csv(filename1):\n",
    "    \n",
    "    pl.subplot(111)\n",
    "    \n",
    "    df = pd.read_csv(filename1)\n",
    "    test_err = (1 - df[\"test_accuracy\"])*100\n",
    "    epoch = df[\"epoch\"]\n",
    "    \n",
    "    pl.plot(epoch,test_err)\n",
    "    \n",
    "    pl.ylabel(\"Validation Error [%]\")\n",
    "    pl.xlabel(\"Epoch\")\n",
    "    pl.title('Test error')\n",
    "    pl.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def plot_err_comp():\n",
    "    \n",
    "    pl.subplot(111)\n",
    "    \n",
    "    filename1 = \"mnist.csv\"\n",
    "    df = pd.read_csv(filename1)\n",
    "    test_err = (1 - df[\"test_accuracy\"])*10000\n",
    "    epoch = df[\"epoch\"]\n",
    "    pl.plot(epoch,test_err,label=\"with L2\")\n",
    "    \n",
    "    filename1 = \"mnist_nol2_minusalpha.csv\"\n",
    "    df = pd.read_csv(filename1)\n",
    "    test_err = (1 - df[\"test_accuracy\"])*10000\n",
    "    epoch = df[\"epoch\"]\n",
    "    pl.plot(epoch,test_err,label=\"SGD minus\")\n",
    "    \n",
    "    filename1 = \"mnist_nol2_plusalpha.csv\"\n",
    "    df = pd.read_csv(filename1)\n",
    "    test_err = (1 - df[\"test_accuracy\"])*10000\n",
    "    epoch = df[\"epoch\"]\n",
    "    pl.plot(epoch,test_err,label=\"SGD plus\")\n",
    "    \n",
    "    \n",
    "    pl.plot([0.,1000.],[160.,160.],ls='-',c='black')\n",
    "    \n",
    "    pl.axis([0.,1000.,80.,220.])\n",
    "    pl.ylabel(\"Number of Errors\")\n",
    "    pl.xlabel(\"Epoch\")\n",
    "    pl.title('Test error')\n",
    "    pl.legend()\n",
    "    pl.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def plot_loss_csv(filename1):\n",
    "    \n",
    "    pl.subplot(111)\n",
    "    \n",
    "    df = pd.read_csv(filename1)\n",
    "    \n",
    "    train_loss = df[\"train_loss\"]\n",
    "    test_loss = df[\"test_loss\"]\n",
    "    epoch = df[\"epoch\"]\n",
    "    \n",
    "    pl.plot(epoch,train_loss,label=\"Train\")\n",
    "    pl.plot(epoch,test_loss,label=\"Test\")\n",
    "    \n",
    "    pl.ylabel(\"Loss\")\n",
    "    pl.xlabel(\"Epoch\")\n",
    "    pl.legend()\n",
    "    pl.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def plot_loss_comb(snippet):\n",
    "    \n",
    "    files = glob.glob(snippet)\n",
    "    print(files)\n",
    "    i=0\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        train = df[\"train_loss\"].values\n",
    "        test  = df[\"test_loss\"].values\n",
    "        epoch  = df[\"epoch\"].values\n",
    "        \n",
    "        if i==0:\n",
    "            train_loss, test_loss = train, test\n",
    "            train_loss_sq, test_loss_sq = train**2, test**2\n",
    "            i=1\n",
    "        else:\n",
    "            train_loss += train\n",
    "            test_loss  += test\n",
    "            \n",
    "            train_loss_sq += train**2\n",
    "            test_loss_sq  += test**2\n",
    "        \n",
    "    train_mean = train_loss/len(files)\n",
    "    test_mean  = test_loss/len(files)\n",
    "    \n",
    "    train_std = np.sqrt(train_loss_sq/len(files) - train_mean**2)\n",
    "    test_std  = np.sqrt(test_loss_sq/len(files) - test_mean**2)\n",
    "    \n",
    "    pl.subplot(111)\n",
    "    \n",
    "    pl.plot(epoch,train_mean, label='Train')\n",
    "    pl.fill_between(epoch, train_mean-train_std, train_mean+train_std, alpha=0.3)\n",
    "    \n",
    "    pl.plot(epoch,test_mean, label='Validation')\n",
    "    pl.fill_between(epoch, test_mean-test_std, test_mean+test_std, alpha=0.3)\n",
    "    \n",
    "    pl.ylabel(\"Loss\")\n",
    "    pl.xlabel(\"Epoch\")\n",
    "    pl.legend()\n",
    "    \n",
    "    pl.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def plot_loss_multi(dataset='cn',N=10):\n",
    "    \n",
    "    if dataset=='cn':\n",
    "        path1 = 'finishedcsv/mirabest_lenet.csv'\n",
    "        path2 = 'finishedcsv/mirabest_CN4lenet.csv'\n",
    "        path3 = 'finishedcsv/mirabest_CN8lenet.csv'\n",
    "        path4 = 'finishedcsv/mirabest_CN16lenet.csv'\n",
    "        #path5 = 'finishedcsv/mirabest_lenet.csv'\n",
    "    elif dataset=='dn':\n",
    "        path1 = 'finishedcsv/mirabest_lenet.csv'\n",
    "        path2 = 'finishedcsv/mirabest_DN4lenet.csv'\n",
    "        path3 = 'finishedcsv/mirabest_DN8lenet.csv'\n",
    "        path4 = 'finishedcsv/mirabest_DN16lenet.csv'\n",
    "        #path5 = 'mb_dn20lenet/mirabest_dnlenet_*.csv'\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    ax = pl.subplot(111)\n",
    "    \n",
    "    files = glob.glob(path1)\n",
    "    i=0\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        test  = df[\"test_loss\"].values\n",
    "        epoch  = df[\"epoch\"].values\n",
    "        \n",
    "        if i==0:\n",
    "            test_loss = test\n",
    "            test_loss_sq = test**2\n",
    "            i=1\n",
    "        else:\n",
    "            test_loss += test\n",
    "            test_loss_sq += test**2\n",
    "        \n",
    "    test_mean  = test_loss/len(files)\n",
    "    test_std  = np.sqrt(test_loss_sq/len(files) - test_mean**2)\n",
    "    \n",
    "    test_mean = np.convolve(test_mean, np.ones(N)/N, mode='valid')\n",
    "    test_std = np.convolve(test_std, np.ones(N)/N, mode='valid')\n",
    "    epoch = np.convolve(epoch, np.ones(N)/N, mode='valid')\n",
    "    print(test_std[-1])\n",
    "    \n",
    "    pl.plot(epoch,test_mean, label='{e}')\n",
    "    pl.fill_between(epoch, test_mean-test_std, test_mean+test_std, alpha=0.3)\n",
    "    \n",
    "    files = glob.glob(path2)\n",
    "    i=0\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        test  = df[\"test_loss\"].values\n",
    "        epoch  = df[\"epoch\"].values\n",
    "        \n",
    "        if i==0:\n",
    "            test_loss = test\n",
    "            test_loss_sq = test**2\n",
    "            i=1\n",
    "        else:\n",
    "            test_loss += test\n",
    "            test_loss_sq += test**2\n",
    "        \n",
    "    test_mean  = test_loss/len(files)\n",
    "    test_std  = np.sqrt(test_loss_sq/len(files) - test_mean**2)\n",
    "    \n",
    "    test_mean = np.convolve(test_mean, np.ones(N)/N, mode='valid')\n",
    "    test_std = np.convolve(test_std, np.ones(N)/N, mode='valid')\n",
    "    epoch = np.convolve(epoch, np.ones(N)/N, mode='valid')\n",
    "    print(test_std[-1])\n",
    "        \n",
    "    if dataset=='cn':\n",
    "        label = r'$C_4$'\n",
    "    elif dataset=='dn':\n",
    "        label = r'$D_4$'\n",
    "    \n",
    "    pl.plot(epoch,test_mean, label=label)\n",
    "    pl.fill_between(epoch, test_mean-test_std, test_mean+test_std, alpha=0.3)\n",
    "    \n",
    "    files = glob.glob(path3)\n",
    "    i=0\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        test  = df[\"test_loss\"].values\n",
    "        epoch  = df[\"epoch\"].values\n",
    "        \n",
    "        if i==0:\n",
    "            test_loss = test\n",
    "            test_loss_sq = test**2\n",
    "            i=1\n",
    "        else:\n",
    "            test_loss += test\n",
    "            test_loss_sq += test**2\n",
    "        \n",
    "    test_mean  = test_loss/len(files)\n",
    "    test_std  = np.sqrt(test_loss_sq/len(files) - test_mean**2)\n",
    "    \n",
    "    test_mean = np.convolve(test_mean, np.ones(N)/N, mode='valid')\n",
    "    test_std = np.convolve(test_std, np.ones(N)/N, mode='valid')\n",
    "    epoch = np.convolve(epoch, np.ones(N)/N, mode='valid')\n",
    "    print(test_std[-1])\n",
    "        \n",
    "    if dataset=='cn':\n",
    "        label = r'$C_8$'\n",
    "    elif dataset=='dn':\n",
    "        label = r'$D_8$'\n",
    "        \n",
    "    pl.plot(epoch,test_mean, label=label)\n",
    "    pl.fill_between(epoch, test_mean-test_std, test_mean+test_std, alpha=0.3)\n",
    "    \n",
    "    files = glob.glob(path4)\n",
    "    i=0\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        test  = df[\"test_loss\"].values\n",
    "        epoch  = df[\"epoch\"].values\n",
    "        \n",
    "        if i==0:\n",
    "            test_loss = test\n",
    "            test_loss_sq = test**2\n",
    "            i=1\n",
    "        else:\n",
    "            test_loss += test\n",
    "            test_loss_sq += test**2\n",
    "        \n",
    "    test_mean  = test_loss/len(files)\n",
    "    test_std  = np.sqrt(test_loss_sq/len(files) - test_mean**2)\n",
    "    \n",
    "    test_mean = np.convolve(test_mean, np.ones(N)/N, mode='valid')\n",
    "    test_std = np.convolve(test_std, np.ones(N)/N, mode='valid')\n",
    "    epoch = np.convolve(epoch, np.ones(N)/N, mode='valid')\n",
    "    print(test_std[-1])\n",
    "        \n",
    "    if dataset=='cn':\n",
    "        label = r'$C_{16}$'\n",
    "    elif dataset=='dn':\n",
    "        label = r'$D_{16}$'\n",
    "    \n",
    "    pl.plot(epoch,test_mean, label=label)\n",
    "    pl.fill_between(epoch, test_mean-test_std, test_mean+test_std, alpha=0.3)\n",
    "    \n",
    "    # files = glob.glob(path5)\n",
    "    # i=0\n",
    "    # for file in files:\n",
    "\n",
    "    #     df = pd.read_csv(file)\n",
    "    \n",
    "    #     test  = df[\"test_loss\"].values\n",
    "    #     epoch  = df[\"epoch\"].values\n",
    "        \n",
    "    #     if i==0:\n",
    "    #         test_loss = test\n",
    "    #         test_loss_sq = test**2\n",
    "    #         i=1\n",
    "    #     else:\n",
    "    #         test_loss += test\n",
    "    #         test_loss_sq += test**2\n",
    "        \n",
    "    # test_mean  = test_loss/len(files)\n",
    "    # test_std  = np.sqrt(test_loss_sq/len(files) - test_mean**2)\n",
    "    \n",
    "    # test_mean = np.convolve(test_mean, np.ones(N)/N, mode='valid')\n",
    "    # test_std = np.convolve(test_std, np.ones(N)/N, mode='valid')\n",
    "    # epoch = np.convolve(epoch, np.ones(N)/N, mode='valid')\n",
    "    # print(test_std[-1])\n",
    "        \n",
    "    # if dataset=='cn':\n",
    "    #     label = r'$C_{20}$'\n",
    "    # elif dataset=='dn':\n",
    "    #     label = r'$D_{20}$'\n",
    "    \n",
    "    # pl.plot(epoch,test_mean, label=label)\n",
    "    # pl.fill_between(epoch, test_mean-test_std, test_mean+test_std, alpha=0.3)\n",
    "    \n",
    "    \n",
    "    pl.ylabel(\"Validation Loss\")\n",
    "    pl.xlabel(\"Epoch\")\n",
    "    \n",
    "    ax.semilogy()\n",
    "    ax.yaxis.set_major_formatter(ScalarFormatter())\n",
    "    ax.yaxis.set_minor_formatter(ScalarFormatter())\n",
    "    \n",
    "    pl.legend()\n",
    "    pl.axis([0,600,0.12,0.45])\n",
    "    \n",
    "    pl.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def plot_err_multi(dataset='dn', N=10):\n",
    "    \n",
    "    if dataset=='cn':\n",
    "        path1 = 'mb_lenet/mirabest_lenet_*.csv'\n",
    "        path2 = 'mb_cn4lenet/mirabest_cnlenet_*.csv'\n",
    "        path3 = 'mb_cn8lenet/mirabest_cnlenet_*.csv'\n",
    "        path4 = 'mb_cn16lenet/mirabest_cnlenet_*.csv'\n",
    "        path5 = 'mb_cn20lenet/mirabest_cnlenet_*.csv'\n",
    "    elif dataset=='dn':\n",
    "        path1 = 'mb_lenet/mirabest_lenet_*.csv'\n",
    "        path2 = 'mb_dn4lenet/mirabest_dnlenet_*.csv'\n",
    "        path3 = 'mb_dn8lenet/mirabest_dnlenet_*.csv'\n",
    "        path4 = 'mb_dn16lenet/mirabest_dnlenet_*.csv'\n",
    "        path5 = 'mb_dn20lenet/mirabest_dnlenet_*.csv'\n",
    "    else:\n",
    "        return\n",
    "        \n",
    "    ax = pl.subplot(111)\n",
    "    \n",
    "    files = glob.glob(path1)\n",
    "    i=0\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        test  = (1 - df[\"test_accuracy\"].values)*100.\n",
    "        epoch  = df[\"epoch\"].values\n",
    "        \n",
    "        if i==0:\n",
    "            test_loss = test\n",
    "            test_loss_sq = test**2\n",
    "            i=1\n",
    "        else:\n",
    "            test_loss += test\n",
    "            test_loss_sq += test**2\n",
    "        \n",
    "    test_mean  = test_loss/len(files)\n",
    "    test_std  = np.sqrt(test_loss_sq/len(files) - test_mean**2)\n",
    "    \n",
    "    test_mean = np.convolve(test_mean, np.ones(N)/N, mode='valid')\n",
    "    test_std = np.convolve(test_std, np.ones(N)/N, mode='valid')\n",
    "    epoch = np.convolve(epoch, np.ones(N)/N, mode='valid')\n",
    "    \n",
    "    pl.plot(epoch,test_mean, label='{e}')\n",
    "    pl.fill_between(epoch, test_mean-test_std, test_mean+test_std, alpha=0.3)\n",
    "    \n",
    "    files = glob.glob(path2)\n",
    "    i=0\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        test  = (1 - df[\"test_accuracy\"].values)*100.\n",
    "        epoch  = df[\"epoch\"].values\n",
    "        \n",
    "        if i==0:\n",
    "            test_loss = test\n",
    "            test_loss_sq = test**2\n",
    "            i=1\n",
    "        else:\n",
    "            test_loss += test\n",
    "            test_loss_sq += test**2\n",
    "        \n",
    "    test_mean  = test_loss/len(files)\n",
    "    test_std  = np.sqrt(test_loss_sq/len(files) - test_mean**2)\n",
    "    \n",
    "    test_mean = np.convolve(test_mean, np.ones(N)/N, mode='valid')\n",
    "    test_std = np.convolve(test_std, np.ones(N)/N, mode='valid')\n",
    "    epoch = np.convolve(epoch, np.ones(N)/N, mode='valid')\n",
    "    \n",
    "    pl.plot(epoch,test_mean, label=r'$C_4$')\n",
    "    pl.fill_between(epoch, test_mean-test_std, test_mean+test_std, alpha=0.3)\n",
    "    \n",
    "    files = glob.glob(path3)\n",
    "    i=0\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        test  = (1 - df[\"test_accuracy\"].values)*100.\n",
    "        epoch  = df[\"epoch\"].values\n",
    "        \n",
    "        if i==0:\n",
    "            test_loss = test\n",
    "            test_loss_sq = test**2\n",
    "            i=1\n",
    "        else:\n",
    "            test_loss += test\n",
    "            test_loss_sq += test**2\n",
    "        \n",
    "    test_mean  = test_loss/len(files)\n",
    "    test_std  = np.sqrt(test_loss_sq/len(files) - test_mean**2)\n",
    "    \n",
    "    test_mean = np.convolve(test_mean, np.ones(N)/N, mode='valid')\n",
    "    test_std = np.convolve(test_std, np.ones(N)/N, mode='valid')\n",
    "    epoch = np.convolve(epoch, np.ones(N)/N, mode='valid')\n",
    "    \n",
    "    pl.plot(epoch,test_mean, label=r'$C_8$')\n",
    "    pl.fill_between(epoch, test_mean-test_std, test_mean+test_std, alpha=0.3)\n",
    "    \n",
    "    files = glob.glob(path4)\n",
    "    i=0\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        test  = (1 - df[\"test_accuracy\"].values)*100.\n",
    "        epoch  = df[\"epoch\"].values\n",
    "        \n",
    "        if i==0:\n",
    "            test_loss = test\n",
    "            test_loss_sq = test**2\n",
    "            i=1\n",
    "        else:\n",
    "            test_loss += test\n",
    "            test_loss_sq += test**2\n",
    "        \n",
    "    test_mean  = test_loss/len(files)\n",
    "    test_std  = np.sqrt(test_loss_sq/len(files) - test_mean**2)\n",
    "    \n",
    "    test_mean = np.convolve(test_mean, np.ones(N)/N, mode='valid')\n",
    "    test_std = np.convolve(test_std, np.ones(N)/N, mode='valid')\n",
    "    epoch = np.convolve(epoch, np.ones(N)/N, mode='valid')\n",
    "    \n",
    "    pl.plot(epoch,test_mean, label=r'$C_{16}$')\n",
    "    pl.fill_between(epoch, test_mean-test_std, test_mean+test_std, alpha=0.3)\n",
    "    \n",
    "    files = glob.glob(path5)\n",
    "    i=0\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        test  = (1 - df[\"test_accuracy\"].values)*100.\n",
    "        epoch  = df[\"epoch\"].values\n",
    "        \n",
    "        if i==0:\n",
    "            test_loss = test\n",
    "            test_loss_sq = test**2\n",
    "            i=1\n",
    "        else:\n",
    "            test_loss += test\n",
    "            test_loss_sq += test**2\n",
    "        \n",
    "    test_mean  = test_loss/len(files)\n",
    "    test_std  = np.sqrt(test_loss_sq/len(files) - test_mean**2)\n",
    "    \n",
    "    test_mean = np.convolve(test_mean, np.ones(N)/N, mode='valid')\n",
    "    test_std = np.convolve(test_std, np.ones(N)/N, mode='valid')\n",
    "    epoch = np.convolve(epoch, np.ones(N)/N, mode='valid')\n",
    "    \n",
    "    pl.plot(epoch,test_mean, label=r'$C_{20}$')\n",
    "    pl.fill_between(epoch, test_mean-test_std, test_mean+test_std, alpha=0.3)\n",
    "    \n",
    "    \n",
    "    pl.ylabel(\"Validation Error [%]\")\n",
    "    pl.xlabel(\"Epoch\")\n",
    "    \n",
    "    ax.semilogy()\n",
    "    ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "    ax.yaxis.set_minor_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "    \n",
    "    pl.legend()\n",
    "    \n",
    "    pl.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def plot_fr_err_order():\n",
    "\n",
    "    nlist = [2,4,8,16,20]\n",
    "    \n",
    "    path = 'lenet/frdeepf_lenet_*'\n",
    "        \n",
    "    files = glob.glob(path)\n",
    "    i=0\n",
    "    for file in files:\n",
    "            \n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        test  = (1 - df[\"test_accuracy\"].values)*100.\n",
    "            \n",
    "        if i==0:\n",
    "            best = np.min(test)\n",
    "            best_sq = np.min(test)**2\n",
    "            i=1\n",
    "        else:\n",
    "            best += np.min(test)\n",
    "            best_sq += np.min(test)**2\n",
    "        \n",
    "    cnn_mean  = best/len(files)\n",
    "    cnn_std  = np.sqrt(best_sq/len(files) - cnn_mean**2)\n",
    "        \n",
    "\n",
    "    cn = []; cn_std = []\n",
    "    dn = []; dn_std = []\n",
    "    for n in nlist:\n",
    "        path = 'cn'+str(n)+'lenet/frdeepf_cnlenet_*'\n",
    "        \n",
    "        files = glob.glob(path)\n",
    "        i=0\n",
    "        for file in files:\n",
    "\n",
    "            df = pd.read_csv(file)\n",
    "    \n",
    "            test  = (1 - df[\"test_accuracy\"].values)*100.\n",
    "            \n",
    "            if i==0:\n",
    "                best = np.min(test)\n",
    "                best_sq = np.min(test)**2\n",
    "                i=1\n",
    "            else:\n",
    "                best += np.min(test)\n",
    "                best_sq += np.min(test)**2\n",
    "        \n",
    "        best_mean  = best/len(files)\n",
    "        best_std  = np.sqrt(best_sq/len(files) - best_mean**2)\n",
    "        \n",
    "        cn.append(best_mean)\n",
    "        cn_std.append(best_std)\n",
    " \n",
    "#        path = 'dn'+str(n)+'lenet/frdeepf_dnlenet_*'\n",
    "#\n",
    "#        files = glob.glob(path)\n",
    "#        i=0\n",
    "#        for file in files:\n",
    "#\n",
    "#            df = pd.read_csv(file)\n",
    "#\n",
    "#            test  = (1 - df[\"test_accuracy\"].values)*100.\n",
    "#\n",
    "#            if i==0:\n",
    "#                best = np.min(test)\n",
    "#                best_sq = np.min(test)**2\n",
    "#                i=1\n",
    "#            else:\n",
    "#                best += np.min(test)\n",
    "#                best_sq += np.min(test)**2\n",
    "#\n",
    "#        best_mean  = best/len(files)\n",
    "#        best_std  = np.sqrt(best_sq/len(files) - best_mean**2)\n",
    "#\n",
    "#        dn.append(best_mean)\n",
    "#        dn_std.append(best_std)\n",
    "\n",
    "    \n",
    "    cn = np.array(cn)\n",
    "    #dn = np.array(dn)\n",
    "    \n",
    "    cn_std = np.array(cn_std)\n",
    "    #dn_std = np.array(dn_std)\n",
    "        \n",
    "    ax = pl.subplot(111)\n",
    "    \n",
    "    ax.plot(nlist, cnn_mean*np.ones(len(nlist)), label = r\"$\\{e\\}$\")\n",
    "    ax.fill_between(nlist, (cnn_mean+cnn_std)*np.ones(len(nlist)), (cnn_mean-cnn_std)*np.ones(len(nlist)), alpha=0.3)\n",
    "        \n",
    "    ax.plot(nlist, cn, label=r\"$C_N$\")\n",
    "    ax.fill_between(nlist, cn+cn_std, cn-cn_std, alpha=0.3)\n",
    "    \n",
    "    #pl.plot(nlist, dn, label=r\"$D_N$\")\n",
    "    #pl.fill_between(nlist, dn+dn_std, dn-dn_std, alpha=0.3)\n",
    "    \n",
    "    pl.ylabel(\"Validation Error [%]\")\n",
    "    pl.xlabel(\"Epoch\")\n",
    "    ax.semilogy()\n",
    "    ax.yaxis.set_major_formatter(ScalarFormatter())\n",
    "    ax.yaxis.set_minor_formatter(ScalarFormatter())\n",
    "    \n",
    "    pl.legend()\n",
    "    \n",
    "    pl.show()\n",
    "    \n",
    "\n",
    "    return\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def plot_mb_err_order(N=10):\n",
    "\n",
    "    nlist = [2,4,6,8,10,12,14,16,20]\n",
    "    \n",
    "    path = 'mb_lenet/mirabest_lenet_*.csv'\n",
    "        \n",
    "    files = glob.glob(path)\n",
    "    i=0\n",
    "    for file in files:\n",
    "            \n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        test  = (1 - df[\"test_accuracy\"].values)*100.\n",
    "            \n",
    "        if i==0:\n",
    "            best = test\n",
    "            best_sq = test**2\n",
    "            i=1\n",
    "        else:\n",
    "            best += test\n",
    "            best_sq += test**2\n",
    "        \n",
    "    cnn_mean  = best/len(files)\n",
    "    cnn_std  = np.sqrt(best_sq/len(files) - cnn_mean**2)\n",
    "        \n",
    "    cnn_mean = np.convolve(cnn_mean, np.ones(N)/N, mode='valid')[-1]\n",
    "    cnn_std = np.convolve(cnn_std, np.ones(N)/N, mode='valid')[-1]\n",
    "\n",
    "    cn = []; cn_std = []\n",
    "    dn = []; dn_std = []\n",
    "    for n in nlist:\n",
    "        path = 'mb_cn'+str(n)+'lenet/mirabest_cnlenet_*.csv'\n",
    "        \n",
    "        files = glob.glob(path)\n",
    "        i=0\n",
    "        for file in files:\n",
    "\n",
    "            df = pd.read_csv(file)\n",
    "    \n",
    "            test  = (1 - df[\"test_accuracy\"].values)*100.\n",
    "            \n",
    "            if i==0:\n",
    "                best = test\n",
    "                best_sq = test**2\n",
    "                i=1\n",
    "            else:\n",
    "                best += test\n",
    "                best_sq += test**2\n",
    "        \n",
    "        best_mean  = best/len(files)\n",
    "        best_std  = np.sqrt(best_sq/len(files) - best_mean**2)\n",
    "        \n",
    "        best_mean = np.convolve(best_mean, np.ones(N)/N, mode='valid')[-1]\n",
    "        best_std = np.convolve(best_std, np.ones(N)/N, mode='valid')[-1]\n",
    "\n",
    "        cn.append(best_mean)\n",
    "        cn_std.append(best_std)\n",
    " \n",
    "        path = 'mb_dn'+str(n)+'lenet/mirabest_dnlenet_*.csv'\n",
    "\n",
    "        files = glob.glob(path)\n",
    "        i=0\n",
    "        for file in files:\n",
    "\n",
    "            df = pd.read_csv(file)\n",
    "\n",
    "            test  = (1 - df[\"test_accuracy\"].values)*100.\n",
    "\n",
    "            if i==0:\n",
    "                best = test\n",
    "                best_sq = test**2\n",
    "                i=1\n",
    "            else:\n",
    "                best += test\n",
    "                best_sq += test**2\n",
    "\n",
    "        best_mean  = best/len(files)\n",
    "        best_std  = np.sqrt(best_sq/len(files) - best_mean**2)\n",
    "\n",
    "        best_mean = np.convolve(best_mean, np.ones(N)/N, mode='valid')[-1]\n",
    "        best_std = np.convolve(best_std, np.ones(N)/N, mode='valid')[-1]\n",
    "\n",
    "        dn.append(best_mean)\n",
    "        dn_std.append(best_std)\n",
    "\n",
    "    \n",
    "    cn = np.array(cn)\n",
    "    dn = np.array(dn)\n",
    "    \n",
    "    cn_std = np.array(cn_std)\n",
    "    dn_std = np.array(dn_std)\n",
    "    print(cn_std)\n",
    "    print(dn_std)\n",
    "    \n",
    "    ax = pl.subplot(111)\n",
    "    \n",
    "    ax.plot(nlist, cnn_mean*np.ones(len(nlist)), label = r\"$\\{e\\}$\")\n",
    "    ax.fill_between(nlist, (cnn_mean+cnn_std)*np.ones(len(nlist)), (cnn_mean-cnn_std)*np.ones(len(nlist)), alpha=0.3)\n",
    "        \n",
    "    ax.plot(nlist, cn, label=r\"$C_N$\")\n",
    "    ax.fill_between(nlist, cn+cn_std, cn-cn_std, alpha=0.3)\n",
    "    \n",
    "    ax.plot(nlist, dn, label=r\"$D_N$\")\n",
    "    ax.fill_between(nlist, dn+dn_std, dn-dn_std, alpha=0.3)\n",
    "    \n",
    "    pl.ylabel(\"Validation Error [%]\")\n",
    "    pl.xlabel(r\"$N$\")\n",
    "    ax.set_ylim([4.5,13.])\n",
    "    ax.semilogy()\n",
    "    ax.xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "    ax.xaxis.set_minor_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "    ax.yaxis.set_minor_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "    \n",
    "    pl.legend()\n",
    "    pl.show()\n",
    "    \n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def test_overlap(beta = 0.1):\n",
    "\n",
    "    n = 50\n",
    "    \n",
    "    x = np.random.normal(0.6,0.1,n)\n",
    "    y = np.random.normal(0.6,0.1,n)\n",
    "    \n",
    "    print(overlapping(x,y,beta))\n",
    "    \n",
    "    return\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def plot_hist(targets, overlaps):\n",
    "\n",
    "    pl.subplot(111)\n",
    "    \n",
    "    x = overlaps[np.where(targets==0)]\n",
    "    y = overlaps[np.where(targets==1)]\n",
    "    \n",
    "    _ = pl.hist(x, bins=20, facecolor='r', alpha=0.75)\n",
    "    _ = pl.hist(y, bins=20, facecolor='b', alpha=0.75)\n",
    "    \n",
    "    pl.show()\n",
    "\n",
    "    return\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def plot_overlap():\n",
    "\n",
    "    path1 = 'lenet_overlap.csv'\n",
    "    path2 = 'dn16_overlap.csv'\n",
    "    \n",
    "    df1 = pd.read_csv(path1)\n",
    "    df2 = pd.read_csv(path2)\n",
    "\n",
    "    targ1 = df1['target'].values\n",
    "    olap1 = df1['average overlap'].values\n",
    "    slap1 = df1['overlap variance'].values\n",
    "\n",
    "    targ2 = df2['target'].values\n",
    "    olap2 = df2['average overlap'].values\n",
    "    slap2 = df2['overlap variance'].values\n",
    "    \n",
    "    pl.subplot(111)\n",
    "    pl.scatter(olap1, slap1, c='r', label=r\"$\\{e\\}$\")\n",
    "    pl.scatter(olap2, slap2, c='b', label=r\"$D_{16}$\")\n",
    "    pl.legend()\n",
    "    pl.show()\n",
    "\n",
    "    return\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def plot_ranked(reverse=False, N=5):\n",
    "\n",
    "    imsize = 150\n",
    "    \n",
    "    crop     = transforms.CenterCrop(imsize)\n",
    "    pad      = transforms.Pad((0, 0, 1, 1), fill=0)\n",
    "    totensor = transforms.ToTensor()\n",
    "    normalise= transforms.Normalize((0.0031,), (0.0350,))\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        crop,\n",
    "        pad,\n",
    "        totensor,\n",
    "        normalise,\n",
    "    ])\n",
    "    \n",
    "    test_data = MBFRConfident('mirabest', train=False, transform=transform)\n",
    "    \n",
    "    path1 = 'lenet_overlap.csv'\n",
    "    path2 = 'dn16_overlap.csv'\n",
    "    \n",
    "    df1 = pd.read_csv(path1)\n",
    "    df2 = pd.read_csv(path2)\n",
    "\n",
    "    targ1 = df1['target'].values\n",
    "    p1    = df1['softmax prob'].values\n",
    "    olap1 = df1['average overlap'].values\n",
    "    slap1 = df1['overlap variance'].values\n",
    "\n",
    "    targ2 = df2['target'].values\n",
    "    p2    = df2['softmax prob'].values\n",
    "    olap2 = df2['average overlap'].values\n",
    "    slap2 = df2['overlap variance'].values\n",
    "    \n",
    "    p1 = [np.array(p1[i].lstrip('[').rstrip(']').split(), dtype=float) for i in range(len(targ1))]\n",
    "    p2 = [np.array(p2[i].lstrip('[').rstrip(']').split(), dtype=float) for i in range(len(targ1))]\n",
    "    \n",
    "    p1 = np.array(p1)\n",
    "    p2 = np.array(p2)\n",
    "    \n",
    "    diff = slap1 - slap2\n",
    "    \n",
    "    if reverse:\n",
    "        i_ep = np.argsort(diff)[::-1]\n",
    "    else:\n",
    "        i_ep = np.argsort(diff)\n",
    "    print(diff[i_ep[0]])\n",
    "    \n",
    "    from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "    fig = pl.figure()\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                     nrows_ncols=(1, N),  # creates 2x2 grid of axes\n",
    "                     axes_pad=0.1,  # pad between axes in inch.\n",
    "                     )\n",
    "    j=0\n",
    "    for i in i_ep[0:N]:\n",
    "        subset_indices = [i] # select your indices here as a list\n",
    "        subset = torch.utils.data.Subset(test_data, subset_indices)\n",
    "        testloader_ordered = torch.utils.data.DataLoader(subset, batch_size=1, shuffle=False)\n",
    "        data, target = iter(testloader_ordered).next()\n",
    "            \n",
    "        grid[j].imshow(np.squeeze(data))  # The AxesGrid object work as a list of axes.\n",
    "        rectangle = pl.Circle((75,75), 25, fill=False, ec=\"white\")\n",
    "        grid[j].add_patch(rectangle)\n",
    "        grid[j].text(5,15,\"Source: {:2d}\".format(i),{'color': 'white', 'fontsize': 10})\n",
    "        grid[j].text(5,145,\"True: {}, Predicted: [{},{}]\".format(targ1[i],np.argmax(p1[i,:]),np.argmax(p2[i,:])),{'color': 'white', 'fontsize': 10})\n",
    "        grid[j].axis('off')\n",
    "        j+=1\n",
    "\n",
    "    #grid[j].axis('off'); grid[j+1].axis('off'); grid[j+2].axis('off')\n",
    "\n",
    "    pl.show()\n",
    "\n",
    "    return\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def plot_loss_norot(N=20):\n",
    "    \n",
    "    path1 = 'mb_lenet/mirabest_lenet_*.csv'\n",
    "    path2 = 'mb_norot/mirabest_lenet_norot*.csv'\n",
    "        \n",
    "    path3 = 'mb_dn16lenet/mirabest_dnlenet_*.csv'\n",
    "    path4 = 'mb_norot/mirabest_dnlenet_norot*.csv'\n",
    "    \n",
    "    \n",
    "    ax = pl.subplot(111)\n",
    "    \n",
    "    files = glob.glob(path1)\n",
    "    i=0\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        test  = df[\"test_loss\"].values\n",
    "        epoch  = df[\"epoch\"].values\n",
    "        \n",
    "        if i==0:\n",
    "            test_loss = test\n",
    "            test_loss_sq = test**2\n",
    "            i=1\n",
    "        else:\n",
    "            test_loss += test\n",
    "            test_loss_sq += test**2\n",
    "        \n",
    "    test_mean  = test_loss/len(files)\n",
    "    test_std  = np.sqrt(test_loss_sq/len(files) - test_mean**2)\n",
    "    \n",
    "    test_mean = np.convolve(test_mean, np.ones(N)/N, mode='valid')\n",
    "    test_std = np.convolve(test_std, np.ones(N)/N, mode='valid')\n",
    "    epoch = np.convolve(epoch, np.ones(N)/N, mode='valid')\n",
    "    print(test_std[-1])\n",
    "    \n",
    "    pl.plot(epoch,test_mean, label='{e}')\n",
    "    pl.fill_between(epoch, test_mean-test_std, test_mean+test_std, alpha=0.3)\n",
    "    \n",
    "    files = glob.glob(path3)\n",
    "    i=0\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        test  = df[\"test_loss\"].values\n",
    "        epoch  = df[\"epoch\"].values\n",
    "        \n",
    "        if i==0:\n",
    "            test_loss = test\n",
    "            test_loss_sq = test**2\n",
    "            i=1\n",
    "        else:\n",
    "            test_loss += test\n",
    "            test_loss_sq += test**2\n",
    "        \n",
    "    test_mean  = test_loss/len(files)\n",
    "    test_std  = np.sqrt(test_loss_sq/len(files) - test_mean**2)\n",
    "    \n",
    "    test_mean = np.convolve(test_mean, np.ones(N)/N, mode='valid')\n",
    "    test_std = np.convolve(test_std, np.ones(N)/N, mode='valid')\n",
    "    epoch = np.convolve(epoch, np.ones(N)/N, mode='valid')\n",
    "        \n",
    "    label = r'$D_16$'\n",
    "    \n",
    "    pl.plot(epoch,test_mean, label=label)\n",
    "    pl.fill_between(epoch, test_mean-test_std, test_mean+test_std, alpha=0.3)\n",
    "    \n",
    "    files = glob.glob(path2)\n",
    "    i=0\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        test  = df[\"test_loss\"].values\n",
    "        epoch  = df[\"epoch\"].values\n",
    "        \n",
    "        if i==0:\n",
    "            test_loss = test\n",
    "            test_loss_sq = test**2\n",
    "            i=1\n",
    "        else:\n",
    "            test_loss += test\n",
    "            test_loss_sq += test**2\n",
    "        \n",
    "    test_mean  = test_loss/len(files)\n",
    "    test_std  = np.sqrt(test_loss_sq/len(files) - test_mean**2)\n",
    "    \n",
    "    test_mean = np.convolve(test_mean, np.ones(N)/N, mode='valid')\n",
    "    test_std = np.convolve(test_std, np.ones(N)/N, mode='valid')\n",
    "    epoch = np.convolve(epoch, np.ones(N)/N, mode='valid')\n",
    "    \n",
    "    pl.plot(epoch, test_mean, ls=':')\n",
    "    \n",
    "    files = glob.glob(path4)\n",
    "    i=0\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        test  = df[\"test_loss\"].values\n",
    "        epoch  = df[\"epoch\"].values\n",
    "        \n",
    "        if i==0:\n",
    "            test_loss = test\n",
    "            test_loss_sq = test**2\n",
    "            i=1\n",
    "        else:\n",
    "            test_loss += test\n",
    "            test_loss_sq += test**2\n",
    "        \n",
    "    test_mean  = test_loss/len(files)\n",
    "    test_std  = np.sqrt(test_loss_sq/len(files) - test_mean**2)\n",
    "    \n",
    "    test_mean = np.convolve(test_mean, np.ones(N)/N, mode='valid')\n",
    "    test_std = np.convolve(test_std, np.ones(N)/N, mode='valid')\n",
    "    epoch = np.convolve(epoch, np.ones(N)/N, mode='valid')\n",
    "    \n",
    "    pl.plot(epoch, test_mean, ls=':')\n",
    "    \n",
    "    \n",
    "    pl.ylabel(\"Validation Loss\")\n",
    "    pl.xlabel(\"Epoch\")\n",
    "    \n",
    "    ax.semilogy()\n",
    "    ax.yaxis.set_major_formatter(ScalarFormatter())\n",
    "    ax.yaxis.set_minor_formatter(ScalarFormatter())\n",
    "    \n",
    "    pl.legend()\n",
    "    \n",
    "    pl.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def plot_loss_restricted(N=10):\n",
    "    \n",
    "    path1 = 'mb_lenet/mirabest_lenet_*.csv'\n",
    "    path2 = 'mb_dn16lenet/mirabest_dnlenet_*.csv'\n",
    "    path3 = 'mb_dn16lenet_rest/mirabest_dnlenet_*.csv'\n",
    "    \n",
    "    ax = pl.subplot(111)\n",
    "    \n",
    "    files = glob.glob(path1)\n",
    "    i=0\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        test  = df[\"test_loss\"].values\n",
    "        epoch  = df[\"epoch\"].values\n",
    "        \n",
    "        if i==0:\n",
    "            test_loss = test\n",
    "            test_loss_sq = test**2\n",
    "            i=1\n",
    "        else:\n",
    "            test_loss += test\n",
    "            test_loss_sq += test**2\n",
    "        \n",
    "    test_mean  = test_loss/len(files)\n",
    "    test_std  = np.sqrt(test_loss_sq/len(files) - test_mean**2)\n",
    "    \n",
    "    test_mean = np.convolve(test_mean, np.ones(N)/N, mode='valid')\n",
    "    test_std = np.convolve(test_std, np.ones(N)/N, mode='valid')\n",
    "    epoch = np.convolve(epoch, np.ones(N)/N, mode='valid')\n",
    "    print(test_std[-1])\n",
    "    \n",
    "    pl.plot(epoch,test_mean, label='{e}')\n",
    "    pl.fill_between(epoch, test_mean-test_std, test_mean+test_std, alpha=0.3)\n",
    "    \n",
    "    files = glob.glob(path2)\n",
    "    i=0\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        test  = df[\"test_loss\"].values\n",
    "        epoch  = df[\"epoch\"].values\n",
    "        \n",
    "        if i==0:\n",
    "            test_loss = test\n",
    "            test_loss_sq = test**2\n",
    "            i=1\n",
    "        else:\n",
    "            test_loss += test\n",
    "            test_loss_sq += test**2\n",
    "        \n",
    "    test_mean  = test_loss/len(files)\n",
    "    test_std  = np.sqrt(test_loss_sq/len(files) - test_mean**2)\n",
    "    \n",
    "    test_mean = np.convolve(test_mean, np.ones(N)/N, mode='valid')\n",
    "    test_std = np.convolve(test_std, np.ones(N)/N, mode='valid')\n",
    "    epoch = np.convolve(epoch, np.ones(N)/N, mode='valid')\n",
    "    print(test_std[-1])\n",
    "        \n",
    "    label = r'$D_{16}$'\n",
    "    \n",
    "    pl.plot(epoch,test_mean, label=label)\n",
    "    pl.fill_between(epoch, test_mean-test_std, test_mean+test_std, alpha=0.3)\n",
    "    \n",
    "    files = glob.glob(path3)\n",
    "    i=0\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        test  = df[\"test_loss\"].values\n",
    "        epoch  = df[\"epoch\"].values\n",
    "        \n",
    "        if i==0:\n",
    "            test_loss = test\n",
    "            test_loss_sq = test**2\n",
    "            i=1\n",
    "        else:\n",
    "            test_loss += test\n",
    "            test_loss_sq += test**2\n",
    "        \n",
    "    test_mean  = test_loss/len(files)\n",
    "    test_std  = np.sqrt(test_loss_sq/len(files) - test_mean**2)\n",
    "    \n",
    "    test_mean = np.convolve(test_mean, np.ones(N)/N, mode='valid')\n",
    "    test_std = np.convolve(test_std, np.ones(N)/N, mode='valid')\n",
    "    epoch = np.convolve(epoch, np.ones(N)/N, mode='valid')\n",
    "    print(test_std[-1])\n",
    "        \n",
    "    label = r'$D_{16}|_1 \\{e\\}$'\n",
    "        \n",
    "    pl.plot(epoch, test_mean, ls=':', label=label)\n",
    "    pl.fill_between(epoch, test_mean-test_std, test_mean+test_std, alpha=0.3)\n",
    "    \n",
    "    pl.ylabel(\"Validation Loss\")\n",
    "    pl.xlabel(\"Epoch\")\n",
    "    \n",
    "    ax.semilogy()\n",
    "    ax.yaxis.set_major_formatter(ScalarFormatter())\n",
    "    ax.yaxis.set_minor_formatter(ScalarFormatter())\n",
    "    \n",
    "    pl.legend()\n",
    "    pl.axis([0,600,0.12,0.45])\n",
    "    \n",
    "    pl.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "def plot_image(i=0, imagename=\"image.jpg\"):\n",
    "\n",
    "    imsize = 150\n",
    "    \n",
    "    crop     = transforms.CenterCrop(imsize)\n",
    "    pad      = transforms.Pad((0, 0, 1, 1), fill=0)\n",
    "    totensor = transforms.ToTensor()\n",
    "    normalise= transforms.Normalize((0.0031,), (0.0350,))\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        crop,\n",
    "        pad,\n",
    "        totensor\n",
    "    ])\n",
    "    \n",
    "    test_data = MBFRConfident('mirabest', train=False, transform=transform)\n",
    "    \n",
    "    subset_indices = [i] # select your indices here as a list\n",
    "    subset = torch.utils.data.Subset(test_data, subset_indices)\n",
    "    testloader_ordered = torch.utils.data.DataLoader(subset, batch_size=1, shuffle=False)\n",
    "    data, target = iter(testloader_ordered).next()\n",
    "        \n",
    "    from torchvision.utils import save_image\n",
    "    save_image(data, imagename)\n",
    "    \n",
    "    return\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "def plot_bar():\n",
    "\n",
    "    N = 3\n",
    "    fri = (2.96, 1.76, 1.71)\n",
    "    frii = (3.24, 2.33, 1.87)\n",
    "\n",
    "    ind = np.arange(N)\n",
    "    width = 0.35\n",
    "    pl.bar(ind, fri, width, color='cyan', label='FRI')\n",
    "    pl.bar(ind + width, frii, width, color='lightgrey',\n",
    "        label='FRII')\n",
    "\n",
    "    pl.ylabel('Average Number of Misclassifications')\n",
    "    \n",
    "    pl.xticks(ind + width / 2, (r'$\\{e\\}$', r'C$_{16}$', r'D$_{16}$'))\n",
    "    pl.legend(loc='best')\n",
    "    \n",
    "    pl.show()\n",
    "\n",
    "    return\n",
    "\n",
    "# -------------------------------------------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
