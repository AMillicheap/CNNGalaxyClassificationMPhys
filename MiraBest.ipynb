{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import sys\n",
    "if sys.version_info[0] == 2:\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import pickle\n",
    "\n",
    "import torch.utils.data as data\n",
    "from torchvision.datasets.utils import download_url, check_integrity\n",
    "\n",
    "\n",
    "class MiraBest_full(data.Dataset):\n",
    "    \"\"\"\n",
    "\n",
    "    Inspired by `HTRU1 <https://as595.github.io/HTRU1/>`_ Dataset.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where directory\n",
    "            ``MiraBest-full.py` exists or will be saved to if download is set to True.\n",
    "        train (bool, optional): If True, creates dataset from training set, otherwise\n",
    "            creates from test set.\n",
    "        transform (callable, optional): A function/transform that takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    base_folder = 'batches'\n",
    "    url = \"http://www.jb.man.ac.uk/research/MiraBest/full_dataset/MiraBest_full_batches.tar.gz\"\n",
    "    filename = \"MiraBest_full_batches.tar.gz\"\n",
    "    tgz_md5 = '965b5daa83b9d8622bb407d718eecb51'\n",
    "    train_list = [\n",
    "                  ['data_batch_1', 'b15ae155301f316fc0b51af16b3c540d'],\n",
    "                  ['data_batch_2', '0bf52cc1b47da591ed64127bab6df49e'],\n",
    "                  ['data_batch_3', '98908045de6695c7b586d0bd90d78893'],\n",
    "                  ['data_batch_4', 'ec9b9b77dc019710faf1ad23f1a58a60'],\n",
    "                  ['data_batch_5', '5190632a50830e5ec30de2973cc6b2e1'],\n",
    "                  ['data_batch_6', 'b7113d89ddd33dd179bf64cb578be78e'],\n",
    "                  ['data_batch_7', '626c866b7610bfd08ac94ca3a17d02a1'],\n",
    "                  ]\n",
    "\n",
    "    test_list = [\n",
    "                 ['test_batch', '5e443302dbdf3c2003d68ff9ac95f08c'],\n",
    "                 ]\n",
    "    meta = {\n",
    "                'filename': 'batches.meta',\n",
    "                'key': 'label_names',\n",
    "                'md5': 'e1b5450577209e583bc43fbf8e851965',\n",
    "                }\n",
    "\n",
    "\n",
    "    def __init__(self, root, train=True,\n",
    "                 transform=None, target_transform=None,\n",
    "                 download=False):\n",
    "\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        if self.train:\n",
    "            downloaded_list = self.train_list\n",
    "        else:\n",
    "            downloaded_list = self.test_list\n",
    "\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "\n",
    "        # now load the picked numpy arrays\n",
    "        for file_name, checksum in downloaded_list:\n",
    "            file_path = os.path.join(self.root, self.base_folder, file_name)\n",
    "\n",
    "            with open(file_path, 'rb') as f:\n",
    "                if sys.version_info[0] == 2:\n",
    "                    entry = pickle.load(f)\n",
    "                else:\n",
    "                    entry = pickle.load(f, encoding='latin1')\n",
    "\n",
    "                self.data.append(entry['data'])\n",
    "                if 'labels' in entry:\n",
    "                    self.targets.extend(entry['labels'])\n",
    "                else:\n",
    "                    self.targets.extend(entry['fine_labels'])\n",
    "\n",
    "        self.data = np.vstack(self.data).reshape(-1, 1, 150, 150)\n",
    "        self.data = self.data.transpose((0, 2, 3, 1))\n",
    "\n",
    "        self._load_meta()\n",
    "\n",
    "    def _load_meta(self):\n",
    "        path = os.path.join(self.root, self.base_folder, self.meta['filename'])\n",
    "        if not check_integrity(path, self.meta['md5']):\n",
    "            raise RuntimeError('Dataset metadata file not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "        with open(path, 'rb') as infile:\n",
    "            if sys.version_info[0] == 2:\n",
    "                data = pickle.load(infile)\n",
    "            else:\n",
    "                data = pickle.load(infile, encoding='latin1')\n",
    "            self.classes = data[self.meta['key']]\n",
    "        self.class_to_idx = {_class: i for i, _class in enumerate(self.classes)}\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = np.reshape(img,(150,150))\n",
    "        img = Image.fromarray(img,mode='L')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        root = self.root\n",
    "        for fentry in (self.train_list + self.test_list):\n",
    "            filename, md5 = fentry[0], fentry[1]\n",
    "            fpath = os.path.join(root, self.base_folder, filename)\n",
    "            if not check_integrity(fpath, md5):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def download(self):\n",
    "        import tarfile\n",
    "\n",
    "        if self._check_integrity():\n",
    "            print('Files already downloaded and verified')\n",
    "            return\n",
    "\n",
    "        download_url(self.url, self.root, self.filename, self.tgz_md5)\n",
    "\n",
    "        # extract file\n",
    "        with tarfile.open(os.path.join(self.root, self.filename), \"r:gz\") as tar:\n",
    "            tar.extractall(path=self.root)\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        tmp = 'train' if self.train is True else 'test'\n",
    "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "        tmp = '    Transforms (if any): '\n",
    "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        tmp = '    Target Transforms (if any): '\n",
    "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        return fmt_str\n",
    "\n",
    "\n",
    "class MBFRConfident(MiraBest_full):\n",
    "\n",
    "    \"\"\"\n",
    "    Child class to load only confident FRI (0) & FRII (1)\n",
    "    [100, 102, 104] and [200, 201]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MBFRConfident, self).__init__(*args, **kwargs)\n",
    "\n",
    "        fr1_list = [0,1,2]\n",
    "        fr2_list = [5,6]\n",
    "        exclude_list = [3,4,7,8,9]\n",
    "\n",
    "        if exclude_list == []:\n",
    "            return\n",
    "        if self.train:\n",
    "            targets = np.array(self.targets)\n",
    "            exclude = np.array(exclude_list).reshape(1, -1)\n",
    "            exclude_mask = ~(targets.reshape(-1, 1) == exclude).any(axis=1)\n",
    "            fr1 = np.array(fr1_list).reshape(1, -1)\n",
    "            fr2 = np.array(fr2_list).reshape(1, -1)\n",
    "            fr1_mask = (targets.reshape(-1, 1) == fr1).any(axis=1)\n",
    "            fr2_mask = (targets.reshape(-1, 1) == fr2).any(axis=1)\n",
    "            targets[fr1_mask] = 0 # set all FRI to Class~0\n",
    "            targets[fr2_mask] = 1 # set all FRII to Class~1\n",
    "            self.data = self.data[exclude_mask]\n",
    "            self.targets = targets[exclude_mask].tolist()\n",
    "        else:\n",
    "            targets = np.array(self.targets)\n",
    "            exclude = np.array(exclude_list).reshape(1, -1)\n",
    "            exclude_mask = ~(targets.reshape(-1, 1) == exclude).any(axis=1)\n",
    "            fr1 = np.array(fr1_list).reshape(1, -1)\n",
    "            fr2 = np.array(fr2_list).reshape(1, -1)\n",
    "            fr1_mask = (targets.reshape(-1, 1) == fr1).any(axis=1)\n",
    "            fr2_mask = (targets.reshape(-1, 1) == fr2).any(axis=1)\n",
    "            targets[fr1_mask] = 0 # set all FRI to Class~0\n",
    "            targets[fr2_mask] = 1 # set all FRII to Class~1\n",
    "            self.data = self.data[exclude_mask]\n",
    "            self.targets = targets[exclude_mask].tolist()\n",
    "\n",
    "class MBFRUncertain(MiraBest_full):\n",
    "\n",
    "    \"\"\"\n",
    "    Child class to load only uncertain FRI (0) & FRII (1)\n",
    "    [110, 112] and [210]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MBFRUncertain, self).__init__(*args, **kwargs)\n",
    "\n",
    "        fr1_list = [3,4]\n",
    "        fr2_list = [7]\n",
    "        exclude_list = [0,1,2,5,6,8,9]\n",
    "\n",
    "        if exclude_list == []:\n",
    "            return\n",
    "        if self.train:\n",
    "            targets = np.array(self.targets)\n",
    "            exclude = np.array(exclude_list).reshape(1, -1)\n",
    "            exclude_mask = ~(targets.reshape(-1, 1) == exclude).any(axis=1)\n",
    "            fr1 = np.array(fr1_list).reshape(1, -1)\n",
    "            fr2 = np.array(fr2_list).reshape(1, -1)\n",
    "            fr1_mask = (targets.reshape(-1, 1) == fr1).any(axis=1)\n",
    "            fr2_mask = (targets.reshape(-1, 1) == fr2).any(axis=1)\n",
    "            targets[fr1_mask] = 0 # set all FRI to Class~0\n",
    "            targets[fr2_mask] = 1 # set all FRII to Class~1\n",
    "            self.data = self.data[exclude_mask]\n",
    "            self.targets = targets[exclude_mask].tolist()\n",
    "        else:\n",
    "            targets = np.array(self.targets)\n",
    "            exclude = np.array(exclude_list).reshape(1, -1)\n",
    "            exclude_mask = ~(targets.reshape(-1, 1) == exclude).any(axis=1)\n",
    "            fr1 = np.array(fr1_list).reshape(1, -1)\n",
    "            fr2 = np.array(fr2_list).reshape(1, -1)\n",
    "            fr1_mask = (targets.reshape(-1, 1) == fr1).any(axis=1)\n",
    "            fr2_mask = (targets.reshape(-1, 1) == fr2).any(axis=1)\n",
    "            targets[fr1_mask] = 0 # set all FRI to Class~0\n",
    "            targets[fr2_mask] = 1 # set all FRII to Class~1\n",
    "            self.data = self.data[exclude_mask]\n",
    "            self.targets = targets[exclude_mask].tolist()\n",
    "\n",
    "class MBHybrid(MiraBest_full):\n",
    "\n",
    "    \"\"\"\n",
    "    Child class to load confident(0) and uncertain (1) hybrid sources\n",
    "    [110, 112] and [210]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MBHybrid, self).__init__(*args, **kwargs)\n",
    "\n",
    "        h1_list = [8]\n",
    "        h2_list = [9]\n",
    "        exclude_list = [0,1,2,3,4,5,6,7]\n",
    "\n",
    "        if exclude_list == []:\n",
    "            return\n",
    "        if self.train:\n",
    "            targets = np.array(self.targets)\n",
    "            exclude = np.array(exclude_list).reshape(1, -1)\n",
    "            exclude_mask = ~(targets.reshape(-1, 1) == exclude).any(axis=1)\n",
    "            h1 = np.array(h1_list).reshape(1, -1)\n",
    "            h2 = np.array(h2_list).reshape(1, -1)\n",
    "            h1_mask = (targets.reshape(-1, 1) == h1).any(axis=1)\n",
    "            h2_mask = (targets.reshape(-1, 1) == h2).any(axis=1)\n",
    "            targets[h1_mask] = 0 # set all FRI to Class~0\n",
    "            targets[h2_mask] = 1 # set all FRII to Class~1\n",
    "            self.data = self.data[exclude_mask]\n",
    "            self.targets = targets[exclude_mask].tolist()\n",
    "        else:\n",
    "            targets = np.array(self.targets)\n",
    "            exclude = np.array(exclude_list).reshape(1, -1)\n",
    "            exclude_mask = ~(targets.reshape(-1, 1) == exclude).any(axis=1)\n",
    "            h1 = np.array(h1_list).reshape(1, -1)\n",
    "            h2 = np.array(h2_list).reshape(1, -1)\n",
    "            h1_mask = (targets.reshape(-1, 1) == h1).any(axis=1)\n",
    "            h2_mask = (targets.reshape(-1, 1) == h2).any(axis=1)\n",
    "            targets[h1_mask] = 0 # set all FRI to Class~0\n",
    "            targets[h2_mask] = 1 # set all FRII to Class~1\n",
    "            self.data = self.data[exclude_mask]\n",
    "            self.targets = targets[exclude_mask].tolist()\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
